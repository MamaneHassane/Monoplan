{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from mpmath import tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apprentissage_batch_pas_dynamique(vecteurs, classifications, dimension_n, pas_alpha_initial, omega_initial):\n",
    "    omega = omega_initial\n",
    "    alpha = pas_alpha_initial\n",
    "    nb_iterations = 0\n",
    "    \n",
    "    print(\"Début de l'apprentissage batch avec pas dynamique...\")\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        delta_omega = np.zeros(dimension_n + 1)\n",
    "        bien_classes = True\n",
    "\n",
    "        for vecteur, classification in zip(vecteurs, classifications):\n",
    "            vecteur_augmente = np.insert(vecteur, 0, 1) \n",
    "            prediction = np.sign(np.dot(omega, vecteur_augmente))\n",
    "            \n",
    "            if prediction != classification: \n",
    "                bien_classes = False\n",
    "                delta_omega += alpha * (classification - prediction) * vecteur_augmente\n",
    "    \n",
    "        omega += delta_omega\n",
    "        nb_iterations += 1\n",
    "\n",
    "        # pas dynamique\n",
    "        if nb_iterations % 100 == 0:\n",
    "            alpha *= 0.5\n",
    "            # print(f\"Iteration {nb_iterations}: ajustement du pas, nouveau alpha = {alpha}\")\n",
    "\n",
    "        if bien_classes:  # si toutes les paires sont correctement classées\n",
    "            break\n",
    "\n",
    "    print(\"Toutes les paires ont été correctement classées.\")\n",
    "    print(f\"Omega final : {omega}\")\n",
    "    print(f\"Nombre d'itérations nécessaires : {nb_iterations}\")\n",
    "\n",
    "    return omega, nb_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour calculer la stabilité d'un vecteur\n",
    "def stabilite(X, to, W):\n",
    "    return (to * np.dot(W, np.insert(X, 0, 1)))/ np.linalg.norm(W)\n",
    "\n",
    "# fonction pour calculer les stabilités\n",
    "def liste_stabilites(vecteurs, classes, w_separateur):\n",
    "    return np.array([stabilite(vecteurs[i], classes[i], w_separateur) for i in range(len(vecteurs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erreur_minimerror(stabilite, beta):\n",
    "    return 1 - tanh((beta*stabilite)/2)\n",
    "\n",
    "def erreur_moyenne_minimerror_l(stabilites, beta):\n",
    "    return 1/2 * np.sum(np.array([erreur_minimerror(stabilite, beta) for stabilite in stabilites]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimerror_l(vecteurs, classes, w_separateur, dimension_n, T=0.5, max_iterations=1000, erreur_limite=0.0, epsilon=1e-1, delta_b0=1e-3):\n",
    "    beta = 1 / T\n",
    "    erreur_precedente = float('inf')\n",
    "    max_beta = 1e3  # Limite supérieure pour beta\n",
    "    min_cosh_value = 1e-7  # Valeur minimale pour stabiliser cosh\n",
    "    max_cosh_input = 20  # Plafond pour l'entrée de cosh\n",
    "\n",
    "    vecteurs = np.array(vecteurs, dtype=float)\n",
    "    classes = np.array(classes, dtype=float)\n",
    "    w_separateur = np.array(w_separateur, dtype=float)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        stabilites = liste_stabilites(vecteurs, classes, w_separateur)\n",
    "        delta_w = np.zeros(dimension_n + 1, dtype=float)\n",
    "        erreur_actuelle = float(erreur_moyenne_minimerror_l(stabilites, beta))\n",
    "\n",
    "        if erreur_actuelle <= erreur_limite:\n",
    "            print(f\"Erreur limite atteinte après {iteration} itérations.\")\n",
    "            return w_separateur, erreur_actuelle\n",
    "\n",
    "        for u, gamma in enumerate(stabilites):\n",
    "            gamma_beta = beta * gamma / 2\n",
    "            if gamma_beta > max_cosh_input:\n",
    "                cosh_value = 0.5 * np.exp(gamma_beta)  # Approximation pour cosh(x) lorsque x est grand\n",
    "            else:\n",
    "                cosh_value = max(np.cosh(gamma_beta), min_cosh_value)\n",
    "            delta_w += -classes[u] * np.insert(vecteurs[u], 0, 1) / (cosh_value ** 2)\n",
    "\n",
    "        w_separateur -= epsilon * (beta / 4) * delta_w\n",
    "        w_separateur /= np.linalg.norm(w_separateur)\n",
    "\n",
    "        beta = min(beta * (1 + delta_b0), max_beta)  # Limiter la croissance de beta\n",
    "\n",
    "        if iteration % 100 == 0 or iteration == max_iterations - 1:\n",
    "            print(f\"Iteration {iteration}: Erreur = {erreur_actuelle:.6f}, Norme W = {np.linalg.norm(w_separateur):.4f}\")\n",
    "\n",
    "        if erreur_actuelle > erreur_precedente:\n",
    "            epsilon *= 0.5\n",
    "        erreur_precedente = erreur_actuelle\n",
    "\n",
    "    print(\"Nombre maximal d'itérations atteint.\")\n",
    "    print(w_separateur)\n",
    "    return w_separateur, erreur_actuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit deux ensembles par exemple à séparer \n",
    "\n",
    "# or\n",
    "or_vectors = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "or_classifications = np.array([-1,1,1,1])\n",
    "\n",
    "# xor\n",
    "xor_vectors = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "xor_classifications = np.array([1,-1,-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00447368,  0.0041919 , -0.00341209])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On définit un omega initial\n",
    "w_initial = np.random.uniform(low=-0.005, high=0.005, size=3)\n",
    "w_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'apprentissage batch avec pas dynamique...\n",
      "Toutes les paires ont été correctement classées.\n",
      "Omega final : [-0.19552632  0.4041919   0.39658791]\n",
      "Nombre d'itérations nécessaires : 6\n",
      "w_separateur: [-0.19552632  0.4041919   0.39658791]\n",
      "nombre itérations: 6\n"
     ]
    }
   ],
   "source": [
    "# on teste notre algorithme batch à pas dynamique\n",
    "w, nb_iter = apprentissage_batch_pas_dynamique(or_vectors, or_classifications, 2, 0.1, w_initial)\n",
    "print(f\"w_separateur: {w}\")\n",
    "print(f\"nombre itérations: {nb_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour généraliser sur un ensemble\n",
    "def classer_ensemble(vecteurs, w_separateur):\n",
    "    return np.array([1 if np.dot(np.insert(vecteur, 0, 1), w_separateur) > 0 else -1 for vecteur in vecteurs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithme_monoplan(w_initial, vecteurs, classifications, pas_alpha_initial, dimension_n=2, max_iterations=100, max_hyperplans=2, T=0.5, erreur_limite=1):\n",
    "    # liste pour stocker les w_separateurs au fil des itérations\n",
    "    w_liste = []  \n",
    "    \n",
    "    # liste pour stocker les classifications au fil des itérations    \n",
    "    classifications_liste = [classifications]\n",
    "    \n",
    "    # les vecteurs changés au cours des itérations \n",
    "    vecteurs_changes = [vecteurs * classifications[:, np.newaxis]]  # Produire un vecteur pondéré dès le début\n",
    "    \n",
    "    # première itération pour initialiser les tableaux\n",
    "    w_sep_premier, _ = minimerror_l(vecteurs, classifications, w_initial, dimension_n, T=T, erreur_limite=erreur_limite)\n",
    "    w_liste.append(w_sep_premier)\n",
    "    \n",
    "    # itérations pour calculer les hyperplans successifs\n",
    "    for i in range(max_hyperplans):\n",
    "        # calculer un nouvel hyperplan avec minimerror_l\n",
    "        w_sep_iter, _ = minimerror_l(vecteurs_changes[i], classifications_liste[i], w_liste[i], dimension_n, T=T, erreur_limite=erreur_limite)\n",
    "        w_liste.append(w_sep_iter)\n",
    "        \n",
    "        # reclasser les données avec le nouvel hyperplan\n",
    "        nouvelles_classifications = classer_ensemble(vecteurs_changes[i], w_sep_iter)\n",
    "        classifications_liste.append(nouvelles_classifications)\n",
    "        \n",
    "        # mettre à jour les vecteurs changés\n",
    "        vecteurs_ponderes = vecteurs * nouvelles_classifications[:, np.newaxis]\n",
    "        vecteurs_changes.append(vecteurs_ponderes)\n",
    "    \n",
    "    # retourner la liste des w_separateurs\n",
    "    return w_liste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Erreur = 2.103909, Norme W = 1.0000\n",
      "Iteration 100: Erreur = 1.934208, Norme W = 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200: Erreur = 1.916372, Norme W = 1.0000\n",
      "Iteration 300: Erreur = 1.894622, Norme W = 1.0000\n",
      "Iteration 400: Erreur = 1.868462, Norme W = 1.0000\n",
      "Iteration 500: Erreur = 1.837462, Norme W = 1.0000\n",
      "Iteration 600: Erreur = 1.801305, Norme W = 1.0000\n",
      "Iteration 700: Erreur = 1.759843, Norme W = 1.0000\n",
      "Iteration 800: Erreur = 1.713142, Norme W = 1.0000\n",
      "Iteration 900: Erreur = 1.661525, Norme W = 1.0000\n",
      "Iteration 999: Erreur = 1.606179, Norme W = 1.0000\n",
      "Nombre maximal d'itérations atteint.\n",
      "[-0.74992891  0.46776416  0.46776416]\n",
      "Iteration 0: Erreur = 1.386832, Norme W = 1.0000\n",
      "Erreur limite atteinte après 9 itérations.\n",
      "Erreur limite atteinte après 0 itérations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.74992891,  0.46776416,  0.46776416]),\n",
       " array([-0.27023716,  0.68079802,  0.68079802]),\n",
       " array([-0.27023716,  0.68079802,  0.68079802])]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_liste_xor = algorithme_monoplan(w_initial, xor_vectors, xor_classifications, 0.01)\n",
    "w_liste_xor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
